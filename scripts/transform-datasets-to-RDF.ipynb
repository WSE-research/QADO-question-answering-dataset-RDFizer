{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform datasets to RDF as defined in the JSON configuration file"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_folder = \"configurations\"\n",
    "configurations = [\n",
    "    # \"qald.json\",\n",
    "    #\"qald.short.json\",\n",
    "    # \"lc-quad.json\",\n",
    "    # \"rubq.json\",\n",
    "    #\"rubq.short.json\",\n",
    "    # \"cwq.json\",\n",
    "    \"mintaka.json\"\n",
    "]\n",
    "\n",
    "service_url = \"http://localhost:8080/json2rdf\" # \"http://webengineering.ins.hs-anhalt.de:41399/json2rdf\"\n",
    "cache_directory = \"/tmp\"\n",
    "stardog_endpoint = \"http://localhost:5820\"\n",
    "stardog_database = \"rdfizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import rdflib\n",
    "import os\n",
    "import owlrl\n",
    "import stardog\n",
    "from stardog import Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stardog.connection.Connection object at 0x7f6bfc15fc40>\n"
     ]
    }
   ],
   "source": [
    "conn = Connection(stardog_database, endpoint=stardog_endpoint, username='admin', password='admin')\n",
    "pprint(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red(s):\n",
    "    return \"\\x1b[31m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "def green(s):\n",
    "    return \"\\x1b[32m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "def yellow(s):\n",
    "    return \"\\x1b[33m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "def blue(s):\n",
    "    return \"\\x1b[34m\" + s + \"\\x1b[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text_to_file(filename, text):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        \n",
    "def read_text_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "    return text\n",
    "\n",
    "def cache_filename_for_url(url):\n",
    "    url = url.split('?')[0]\n",
    "    return url.replace(\"/\", \"\").replace(\":\", \"\").replace(\".\", \"\")\n",
    "\n",
    "def drop_graph(conn, graph):\n",
    "    try:\n",
    "        query = f\"\"\"DROP GRAPH <{graph}>\"\"\"\n",
    "        conn.update(query)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def load_data_into_graph(conn, graph, filename):\n",
    "    #query = f\"\"\"CREATE GRAPH <{graph}>\"\"\"\n",
    "    #conn.update(query)\n",
    "    conn.begin()\n",
    "    conn.add(stardog.content.File(filename), graph_uri=graph)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def get_count_from_result(results):\n",
    "    for row in results[\"results\"][\"bindings\"]:\n",
    "        count = row[\"count\"][\"value\"]\n",
    "        return int(count)\n",
    "\n",
    "def get_number_of_triples_in_graph(conn, graph):\n",
    "    results = conn.select(f\"SELECT (COUNT(DISTINCT ?s) AS ?count) FROM <{graph}> {{ ?s ?p ?o }}\")\n",
    "    return get_count_from_result(results)\n",
    "\n",
    "def get_number_of_questions_in_graph(conn, graph):\n",
    "    query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "    SELECT (COUNT(DISTINCT ?s) AS ?count) FROM <{graph}> WHERE {{\n",
    "        ?s a ?question .\n",
    "        ?question rdfs:subClassOf <urn:qa:benchmark#Question> . }}\"\"\"\n",
    "\n",
    "    results = conn.select(query)\n",
    "    return int(get_count_from_result(results))\n",
    "\n",
    "def get_number_of_valid_questions_in_graph(conn, graph):\n",
    "    query = f\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "        SELECT (COUNT(DISTINCT ?question) AS ?count)\n",
    "        FROM <{graph}>\n",
    "        WHERE {{\n",
    "            VALUES ?HasQuestionTextProperty {{\n",
    "                <urn:qa:benchmark#questionEng> # RuBQ\n",
    "                <urn:qa:benchmark#questionText> # RuBQ\n",
    "                <urn:qa:benchmark#hasQuestion>  # QALD\n",
    "            }} # needs to be aligned using OWLRL\n",
    "            \n",
    "            VALUES ?hasAnswerProperty {{\n",
    "                <urn:qa:benchmark#hasAnswer> # QALD\n",
    "                <urn:qa:benchmark#answer> # RuBQ\n",
    "            }}\n",
    "            \n",
    "            VALUES ?hasQueryProperty {{\n",
    "                <urn:qa:benchmark#hasSPARQLQuery> # QALD\n",
    "                <urn:qa:benchmark#query> #RuBQ\n",
    "            }}\n",
    "            \n",
    "            ?question a ?questionType .\n",
    "            ?question ?hasQueryProperty ?query .\n",
    "            ?question ?hasAnswerProperty ?answer .\n",
    "            ?question ?hasQuestionTextProperty ?questionText .\n",
    "            ?questionType rdfs:subClassOf <urn:qa:benchmark#Question> .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    #print(query)\n",
    "    result = conn.select(query)\n",
    "    count_valid_questions = get_count_from_result(result)\n",
    "    \n",
    "    return count_valid_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push all data to Stardog and retrieve statistics about each dataset using SPARQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3296669   6057 triples \u001B[31m  2000 questions\u001B[0m \u001B[32m  2000 valid questions\u001B[0m \t Mintaka dev \t https://raw.githubusercontent.com/amazon-science/mintaka/main/data/mintaka_dev.json\n",
      "   6568887  12057 triples \u001B[31m  4000 questions\u001B[0m \u001B[32m  4000 valid questions\u001B[0m \t Mintaka test \t https://raw.githubusercontent.com/amazon-science/mintaka/main/data/mintaka_test.json\n",
      "  23068679  42057 triples \u001B[31m 14000 questions\u001B[0m \u001B[32m 14000 valid questions\u001B[0m \t Mintaka train \t https://raw.githubusercontent.com/amazon-science/mintaka/main/data/mintaka_train.json\n"
     ]
    }
   ],
   "source": [
    "for configuration_filename in configurations:\n",
    "    configuration_list = json.load(open(configurations_folder + \"/\" + configuration_filename))\n",
    "    \n",
    "    for configuration in configuration_list:\n",
    "        #pprint(configuration)\n",
    "        \n",
    "        cache_filename = cache_filename_for_url(configuration[\"filePath\"]) + \".ttl\"\n",
    "        \n",
    "        if not os.path.isfile(cache_directory + \"/\" + cache_filename):\n",
    "            post_data = {   \n",
    "                \"filePath\": configuration[\"filePath\"],\n",
    "                \"homepage\": configuration[\"homepage\"],\n",
    "                \"format\": configuration[\"format\"],\n",
    "                \"label\": configuration[\"label\"],\n",
    "            }\n",
    "            \n",
    "            #pprint(post_data)\n",
    "            turtle_data = requests.post(service_url, json=post_data, headers={'Content-Type': 'application/json'})\n",
    "\n",
    "            if not turtle_data.ok:\n",
    "                print(configuration[\"label\"], turtle_data.text, \"skipping\")\n",
    "                continue\n",
    "\n",
    "            write_text_to_file(cache_directory + \"/\" + cache_filename, turtle_data.text)\n",
    "\n",
    "        try:\n",
    "            turtle_data_as_text = read_text_from_file(cache_directory + \"/\" + cache_filename)\n",
    "           \n",
    "            ### TOO SLOW \n",
    "            #graph = rdflib.Graph()\n",
    "            #graph.parse(cache_directory + \"/\" + cache_filename, format=\"turtle\")\n",
    "            #owlrl.DeductiveClosure(owlrl.OWLRL_Semantics).expand(graph)\n",
    "            \n",
    "            graph = configuration[\"filePath\"]\n",
    "            \n",
    "            # init graph\n",
    "            drop_graph(conn, graph)\n",
    "            load_data_into_graph(conn, graph, cache_directory + \"/\" + cache_filename)\n",
    "            \n",
    "            # stats\n",
    "            number_of_triples_in_graph = get_number_of_triples_in_graph(conn, graph)\n",
    "            number_of_questions_in_graph = get_number_of_questions_in_graph(conn, graph)\n",
    "            number_of_valid_questions_in_graph = get_number_of_valid_questions_in_graph(conn, graph)\n",
    "            \n",
    "            # create colorful output \n",
    "            number_of_triples_in_graph_output = \"%6d triples\" % (number_of_triples_in_graph,)\n",
    "            if number_of_triples_in_graph == 0:\n",
    "                number_of_triples_in_graph_output = red(number_of_triples_in_graph_output)\n",
    "                \n",
    "            number_of_questions_in_graph_output = \"%6d questions\" % (number_of_questions_in_graph,)\n",
    "            if number_of_triples_in_graph == 3 * number_of_questions_in_graph + 1 and number_of_questions_in_graph != 0:\n",
    "                number_of_questions_in_graph_output = green(number_of_questions_in_graph_output)\n",
    "            else:\n",
    "                number_of_questions_in_graph_output = red(number_of_questions_in_graph_output)\n",
    "            \n",
    "            number_of_valid_questions_in_graph_output = \"%6d valid questions\" % (number_of_valid_questions_in_graph,)\n",
    "            if number_of_valid_questions_in_graph == number_of_questions_in_graph and number_of_valid_questions_in_graph != 0:\n",
    "                number_of_valid_questions_in_graph_output = green(number_of_valid_questions_in_graph_output)\n",
    "            else:\n",
    "                number_of_valid_questions_in_graph_output = red(number_of_valid_questions_in_graph_output)\n",
    "            \n",
    "            print(\"%10d\" % (len(turtle_data_as_text),), number_of_triples_in_graph_output, number_of_questions_in_graph_output, number_of_valid_questions_in_graph_output, \"\\t\", configuration[\"label\"], \"\\t\", configuration[\"filePath\"])\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(\"    ERROR\", \"\\t\", configuration[\"label\"],\"\\t\", configuration[\"filePath\"], e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
