{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform datasets to RDF as defined in the JSON configuration file"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_folder = \"configurations\"\n",
    "configurations = [\n",
    "    \"qald.json\",\n",
    "    #\"qald.short.json\",\n",
    "    \"lc-quad.json\",\n",
    "    \"rubq.json\",\n",
    "    #\"rubq.short.json\",\n",
    "    \"cwq.json\",\n",
    "    \"mintaka.json\"\n",
    "]\n",
    "\n",
    "service_url = \"http://localhost:8080/json2rdf\" # \"http://webengineering.ins.hs-anhalt.de:41399/json2rdf\"\n",
    "cache_directory = \"/tmp\"\n",
    "stardog_endpoint = \"http://localhost:5820\"\n",
    "stardog_database = \"rdfizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import rdflib\n",
    "import os\n",
    "import owlrl\n",
    "import stardog\n",
    "from stardog import Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stardog.connection.Connection object at 0x7fcf50160250>\n"
     ]
    }
   ],
   "source": [
    "conn = Connection(stardog_database, endpoint=stardog_endpoint, username='admin', password='admin')\n",
    "pprint(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red(s):\n",
    "    return \"\\x1b[31m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "def green(s):\n",
    "    return \"\\x1b[32m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "def yellow(s):\n",
    "    return \"\\x1b[33m\" + s + \"\\x1b[0m\"\n",
    "\n",
    "def blue(s):\n",
    "    return \"\\x1b[34m\" + s + \"\\x1b[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text_to_file(filename, text):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        \n",
    "def read_text_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "    return text\n",
    "\n",
    "def cache_filename_for_url(url):\n",
    "    url = url.split('?')[0]\n",
    "    return url.replace(\"/\", \"\").replace(\":\", \"\").replace(\".\", \"\")\n",
    "\n",
    "def drop_graph(conn, graph):\n",
    "    try:\n",
    "        query = f\"\"\"DROP GRAPH <{graph}>\"\"\"\n",
    "        conn.update(query)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def load_data_into_graph(conn, graph, filename):\n",
    "    #query = f\"\"\"CREATE GRAPH <{graph}>\"\"\"\n",
    "    #conn.update(query)\n",
    "    conn.begin()\n",
    "    conn.add(stardog.content.File(filename), graph_uri=graph)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def get_count_from_result(results):\n",
    "    for row in results[\"results\"][\"bindings\"]:\n",
    "        count = row[\"count\"][\"value\"]\n",
    "        return int(count)\n",
    "\n",
    "def get_number_of_triples_in_graph(conn, graph):\n",
    "    results = conn.select(f\"SELECT (COUNT(DISTINCT ?s) AS ?count) FROM <{graph}> {{ ?s ?p ?o }}\")\n",
    "    return get_count_from_result(results)\n",
    "\n",
    "def get_number_of_questions_in_graph(conn, graph):\n",
    "    query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "    SELECT (COUNT(DISTINCT ?s) AS ?count) FROM <{graph}> WHERE {{\n",
    "        ?s a ?question .\n",
    "        ?question rdfs:subClassOf <urn:qado#Question> . }}\"\"\"\n",
    "\n",
    "    results = conn.select(query)\n",
    "    return int(get_count_from_result(results))\n",
    "\n",
    "def get_number_of_valid_questions_in_graph(conn, graph):\n",
    "    query = f\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "        SELECT (COUNT(DISTINCT ?question) AS ?count)\n",
    "        FROM <{graph}>\n",
    "        WHERE {{\n",
    "            VALUES ?HasQuestionTextProperty {{\n",
    "                <urn:qado#questionEng> # RuBQ\n",
    "                <urn:qado#questionText> # RuBQ\n",
    "                <urn:qado#hasQuestion>  # QALD\n",
    "            }} # needs to be aligned using OWLRL\n",
    "            \n",
    "            VALUES ?hasAnswerProperty {{\n",
    "                <urn:qado#hasAnswer> # QALD\n",
    "                <urn:qado#answer> # RuBQ\n",
    "            }}\n",
    "            \n",
    "            VALUES ?hasQueryProperty {{\n",
    "                <urn:qado#hasSparqlQuery> # QALD\n",
    "                <urn:qado#query> #RuBQ\n",
    "            }}\n",
    "            \n",
    "            ?question a ?questionType .\n",
    "            ?question ?hasQueryProperty ?query .\n",
    "            ?question ?hasAnswerProperty ?answer .\n",
    "            ?question ?hasQuestionTextProperty ?questionText .\n",
    "            ?questionType rdfs:subClassOf <urn:qado#Question> .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    #print(query)\n",
    "    result = conn.select(query)\n",
    "    count_valid_questions = get_count_from_result(result)\n",
    "    \n",
    "    return count_valid_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push all data to Stardog and retrieve statistics about each dataset using SPARQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    829003   1114 triples \u001B[31m   340 questions\u001B[0m \u001B[32m   340 valid questions\u001B[0m \t QALD 5 train \t https://raw.githubusercontent.com/ag-sc/QALD/master/5/data/qald-5_train.json\n",
      "QALD 6 train datacube Not a valid (absolute) IRI: null8193760 skipping\n",
      "     91405    241 triples \u001B[31m    49 questions\u001B[0m \u001B[32m    49 valid questions\u001B[0m \t QALD 6 train hybrid \t https://github.com/ag-sc/QALD/raw/master/6/data/qald-6-train-hybrid.json\n",
      "    618764   1144 triples \u001B[31m   350 questions\u001B[0m \u001B[32m   350 valid questions\u001B[0m \t QALD 6 train multilingual raw \t https://github.com/ag-sc/QALD/raw/master/6/data/qald-6-train-multilingual-raw.json\n",
      "   2219618   1144 triples \u001B[31m   350 questions\u001B[0m \u001B[32m   350 valid questions\u001B[0m \t QALD 6 train multilingual \t https://github.com/ag-sc/QALD/raw/master/6/data/qald-6-train-multilingual.json\n",
      "QALD 7 train multilingual Not a valid (absolute) IRI: null50035 skipping\n",
      "QALD 7 test multilingual Not a valid (absolute) IRI: null73 skipping\n",
      "QALD 8 train multilingual Not a valid (absolute) IRI: nullfalse skipping\n",
      "     82900    217 triples \u001B[31m    41 questions\u001B[0m \u001B[32m    41 valid questions\u001B[0m \t QALD 8 test multilingual \t https://github.com/ag-sc/QALD/raw/master/8/data/qald-8-test-multilingual.json?raw=true\n",
      "   4475453    502 triples \u001B[31m   136 questions\u001B[0m \u001B[32m   136 valid questions\u001B[0m \t QALD 9 plus test wikidata \t https://raw.githubusercontent.com/KGQA/QALD_9_plus/main/data/qald_9_plus_test_wikidata.json\n",
      "   8638256   1207 triples \u001B[31m   371 questions\u001B[0m \u001B[32m   371 valid questions\u001B[0m \t QALD 9 plus train wikidata \t https://raw.githubusercontent.com/KGQA/QALD_9_plus/main/data/qald_9_plus_train_wikidata.json\n",
      "    788943    544 triples \u001B[31m   150 questions\u001B[0m \u001B[32m   150 valid questions\u001B[0m \t QALD 9 plus test dbpedia \t https://raw.githubusercontent.com/KGQA/QALD_9_plus/main/data/qald_9_plus_test_dbpedia.json\n",
      "   3402214   1318 triples \u001B[31m   408 questions\u001B[0m \u001B[32m   408 valid questions\u001B[0m \t QALD 9 plus train dbpedia \t https://raw.githubusercontent.com/KGQA/QALD_9_plus/main/data/qald_9_plus_train_dbpedia.json\n",
      "    743346   1276 triples \u001B[31m   394 questions\u001B[0m \u001B[32m   394 valid questions\u001B[0m \t QALD 10 \t https://raw.githubusercontent.com/KGQA/QALD_10/main/data/qald_10/qald_10.json\n",
      "   1047341   3094 triples \u001B[31m  1000 questions\u001B[0m \u001B[32m  1000 valid questions\u001B[0m \t lcquad 1.0 test en de \t https://figshare.com/ndownloader/files/23454047\n",
      "   4140608  12085 triples \u001B[31m  3997 questions\u001B[0m \u001B[32m  3997 valid questions\u001B[0m \t lcquad 1.0 train en de \t https://figshare.com/ndownloader/files/23454050\n",
      "lcquad 2.0 train Request timeout has expired [url=http://demos.swe.htwk-leipzig.de:40168/data2rdf, request_timeout=unknown ms] skipping\n",
      "   9242963  18232 triples \u001B[31m  6046 questions\u001B[0m \u001B[32m  6046 valid questions\u001B[0m \t lcquad 2.0 test \t https://figshare.com/ndownloader/files/15738818\n",
      "    289002    994 triples \u001B[31m   300 questions\u001B[0m \u001B[32m   300 valid questions\u001B[0m \t RuBQ 1.0 dev \t https://github.com/vladislavneon/RuBQ/raw/master/RuBQ_1.0/RuBQ_1.0_dev.json?raw=true\n",
      "   1091017   3694 triples \u001B[31m  1200 questions\u001B[0m \u001B[32m  1200 valid questions\u001B[0m \t RuBQ 1.0 test \t https://github.com/vladislavneon/RuBQ/raw/master/RuBQ_1.0/RuBQ_1.0_test.json?raw=true\n",
      "    537327   1834 triples \u001B[31m   580 questions\u001B[0m \u001B[32m   580 valid questions\u001B[0m \t RuBQ 2.0 dev \t https://github.com/vladislavneon/RuBQ/raw/master/RuBQ_2.0/RuBQ_2.0_dev.json?raw=true\n",
      "   2095782   7084 triples \u001B[31m  2330 questions\u001B[0m \u001B[32m  2330 valid questions\u001B[0m \t RuBQ 2.0 test \t https://github.com/vladislavneon/RuBQ/raw/master/RuBQ_2.0/RuBQ_2.0_test.json?raw=true\n",
      "   6120612  11722 triples \u001B[31m  3519 questions\u001B[0m \u001B[32m  3519 valid questions\u001B[0m \t CWQ dev \t https://www.dropbox.com/sh/7pkwkrfnwqhsnpo/AADH8beLbOUWxwvY_K38E3ADa/ComplexWebQuestions_dev.json?dl=1\n",
      "   5333148  10687 triples \u001B[31m  3531 questions\u001B[0m \u001B[32m  3531 valid questions\u001B[0m \t CWQ test \t https://www.dropbox.com/sh/7pkwkrfnwqhsnpo/AABr4ysSy_Tg8Wfxww4i_UWda/ComplexWebQuestions_test.json?dl=1\n",
      "CWQ train Request timeout has expired [url=http://demos.swe.htwk-leipzig.de:40168/data2rdf, request_timeout=unknown ms] skipping\n",
      "    ERROR \t Mintaka dev \t https://raw.githubusercontent.com/amazon-science/mintaka/main/data/mintaka_dev.json [500] TXHRE2: There was a fatal failure during preparation of 1e87401e-72a9-4f66-872a-957b26b63408 com.stardog.stark.io.InvalidRDF: Expected a letter, found '%' [L629]\n",
      "    ERROR \t Mintaka test \t https://raw.githubusercontent.com/amazon-science/mintaka/main/data/mintaka_test.json Already in a transaction\n",
      "Mintaka train Request timeout has expired [url=http://demos.swe.htwk-leipzig.de:40168/data2rdf, request_timeout=unknown ms] skipping\n"
     ]
    }
   ],
   "source": [
    "for configuration_filename in configurations:\n",
    "    configuration_list = json.load(open(configurations_folder + \"/\" + configuration_filename))\n",
    "    \n",
    "    for configuration in configuration_list:\n",
    "        #pprint(configuration)\n",
    "        \n",
    "        cache_filename = cache_filename_for_url(configuration[\"filePath\"]) + \".ttl\"\n",
    "        \n",
    "        if not os.path.isfile(cache_directory + \"/\" + cache_filename):\n",
    "            post_data = {   \n",
    "                \"filePath\": configuration[\"filePath\"],\n",
    "                \"homepage\": configuration[\"homepage\"],\n",
    "                \"format\": configuration[\"format\"],\n",
    "                \"label\": configuration[\"label\"],\n",
    "            }\n",
    "            \n",
    "            #pprint(post_data)\n",
    "            turtle_data = requests.post(service_url, json=post_data, headers={'Content-Type': 'application/json'})\n",
    "\n",
    "            if not turtle_data.ok:\n",
    "                print(configuration[\"label\"], turtle_data.text, \"skipping\")\n",
    "                continue\n",
    "\n",
    "            write_text_to_file(cache_directory + \"/\" + cache_filename, turtle_data.text)\n",
    "\n",
    "        try:\n",
    "            turtle_data_as_text = read_text_from_file(cache_directory + \"/\" + cache_filename)\n",
    "           \n",
    "            ### TOO SLOW \n",
    "            #graph = rdflib.Graph()\n",
    "            #graph.parse(cache_directory + \"/\" + cache_filename, format=\"turtle\")\n",
    "            #owlrl.DeductiveClosure(owlrl.OWLRL_Semantics).expand(graph)\n",
    "            \n",
    "            graph = configuration[\"filePath\"]\n",
    "            \n",
    "            # init graph\n",
    "            drop_graph(conn, graph)\n",
    "            load_data_into_graph(conn, graph, cache_directory + \"/\" + cache_filename)\n",
    "            \n",
    "            # stats\n",
    "            number_of_triples_in_graph = get_number_of_triples_in_graph(conn, graph)\n",
    "            number_of_questions_in_graph = get_number_of_questions_in_graph(conn, graph)\n",
    "            number_of_valid_questions_in_graph = get_number_of_valid_questions_in_graph(conn, graph)\n",
    "            \n",
    "            # create colorful output \n",
    "            number_of_triples_in_graph_output = \"%6d triples\" % (number_of_triples_in_graph,)\n",
    "            if number_of_triples_in_graph == 0:\n",
    "                number_of_triples_in_graph_output = red(number_of_triples_in_graph_output)\n",
    "                \n",
    "            number_of_questions_in_graph_output = \"%6d questions\" % (number_of_questions_in_graph,)\n",
    "            if number_of_triples_in_graph == 3 * number_of_questions_in_graph + 1 and number_of_questions_in_graph != 0:\n",
    "                number_of_questions_in_graph_output = green(number_of_questions_in_graph_output)\n",
    "            else:\n",
    "                number_of_questions_in_graph_output = red(number_of_questions_in_graph_output)\n",
    "            \n",
    "            number_of_valid_questions_in_graph_output = \"%6d valid questions\" % (number_of_valid_questions_in_graph,)\n",
    "            if number_of_valid_questions_in_graph == number_of_questions_in_graph and number_of_valid_questions_in_graph != 0:\n",
    "                number_of_valid_questions_in_graph_output = green(number_of_valid_questions_in_graph_output)\n",
    "            else:\n",
    "                number_of_valid_questions_in_graph_output = red(number_of_valid_questions_in_graph_output)\n",
    "            \n",
    "            print(\"%10d\" % (len(turtle_data_as_text),), number_of_triples_in_graph_output, number_of_questions_in_graph_output, number_of_valid_questions_in_graph_output, \"\\t\", configuration[\"label\"], \"\\t\", configuration[\"filePath\"])\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(\"    ERROR\", \"\\t\", configuration[\"label\"],\"\\t\", configuration[\"filePath\"], e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
